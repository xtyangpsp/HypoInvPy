{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86114159-3c43-4c07-b4be-96dce5543a4e",
   "metadata": {},
   "source": [
    "# Examples of running HypoInvPy with utility functions\n",
    "The examples use the phase data from running EQTransformer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "470ddf2d-5458-4ebf-8f37-f54b3f6502ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys,glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hypoinvpy import core as hc\n",
    "from hypoinvpy import utils\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59f75cc-8de3-465a-b68b-a37424c4c2f1",
   "metadata": {},
   "source": [
    "## Convert station information from json database to CSV\n",
    "The example here uses the *.json file saved by EQTransforer downloading step. The CSV file is for general purpose. To reformat it for HypoInverse code, please see the next example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d97baf2-4b28-4b6e-8fdc-efe446c128ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "infile='input/EQT_station_list.json'\n",
    "utils.stainfo_json2csv(infile,outfile='input/EQT_station_list.csv')\n",
    "stainfo=utils.stainfo_json2csv(infile)\n",
    "print(stainfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd5514d-57de-4880-925b-4c9a4ff2b9a6",
   "metadata": {},
   "source": [
    "## Reformat station information for HypoInverse code.\n",
    "The `HypoInvPy.core.reformat_stainfo()` function takes input in `json` or `csv` format. See the source code or use `help()` to get detailed usage information of this function. \n",
    "\n",
    "* `force_channel_type` option is to force all channels to the specified type. This is because in some earthquake detection and association steps, the original channel types might be lost, making it impossible to link the phase data with station information.\n",
    "* `rename_component_dict` option is to rename component names. This is needec when some components originally having 1 or 2 in the names. These original names sometimes are not kept through the earthquake detection and association steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1702fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc.reformat_stainfo(infile,'input/EQT_station_list.sta',informat='json',force_channel_type='HH',\n",
    "                   rename_component_dict={'1':'N','2':'E'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479874f2-b954-4081-baa2-726fedd93b07",
   "metadata": {},
   "source": [
    "## Setup parameters for HypoInverse code\n",
    "Major parameters to run the code are carried through with a container class named `HypoInvPy.core.HypoInvConfig()`. This class is simplified from the `config()` class in `Hypo-Interface-Py`. In `HypoInvPy`, I also reduced the number of metadata/parameters, to focus only on required key parameters.\n",
    "\n",
    "Examples here use the phase information directly from the `EQTransformer` association step. The station information file has been reformated as shown in the previous cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3298b21d-8733-4de3-93af-92c277b2aa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified from https://github.com/YijianZhou/Hypo-Interface-Py\n",
    "phase_file='input/EQT_Y2000.phs'\n",
    "station_file='input/EQT_station_list.sta'\n",
    "pmodel='input/velo_p_eg.cre'\n",
    "smodel='input/velo_s_eg.cre'\n",
    "lat_code='N'\n",
    "lon_code='W'\n",
    "depth_try_list=np.arange(0,20,1)\n",
    "min_nsta=4 #minimum number of stations to relocate the earthquake. 4 is recommeneded as the minimum to get a reliable location.\n",
    "keep_summary_files=False #keep intermediate summary files from each relocation run?\n",
    "outputdir='output'\n",
    "\n",
    "cfg = hc.HypoInvConfig(phase_file=phase_file,station_file=station_file,\n",
    "                       pmodel=pmodel,smodel=smodel,min_nsta=min_nsta,\n",
    "                      lat_code=lat_code,lon_code=lon_code,ztrlist=depth_try_list)\n",
    "#file names for the final summary catalogs.\n",
    "out_bad = '%s/%s_bad.csv'%(outputdir,cfg.run_tag)\n",
    "out_good = '%s/%s_good.csv'%(outputdir,cfg.run_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72a28e1-307a-4ee6-a4ec-7df9543adc1d",
   "metadata": {},
   "source": [
    "## Run hypoinverse through the interface\n",
    "This is the key step to run hypoinverse. I kept the way Hypo-Interface-Py uses running the code on a series of initial depths. This list is specified as `ztrlist` in the configuration step above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca738e6-76dd-4a6b-80a6-8c7b8f904f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. produce parameter files for each testing initial depth.\n",
    "hypparfiledir='input'\n",
    "hypparfilelist=hc.generate_parfile(cfg,hypparfiledir,outdir=outputdir)\n",
    "\n",
    "# 2. Run hypoinverse with all parameter files.\n",
    "hc.run_hypoinv(hypparfilelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c2b5ef-69c6-4958-8947-97be89f70536",
   "metadata": {},
   "source": [
    "## Extract inversion results based on quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454a9961-fdd6-4062-8f23-b7e50bfeb645",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('converting output sum files')\n",
    "summary_filelist=glob.glob('%s/%s-*.sum'%(outputdir,cfg.run_tag))\n",
    "\n",
    "hc.merge_summary(summary_filelist,out_good,out_bad,lat_code,lon_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03ffc060-f5c4-4376-bc25-400b182413c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove intermidiate files\n",
    "for fname in glob.glob('fort.*'): os.unlink(fname)\n",
    "for fname in glob.glob('input/%s-*.hyp'%cfg.run_tag): os.unlink(fname)\n",
    "if not keep_summary_files:\n",
    "    for fname in glob.glob(outputdir+'/'+cfg.run_tag+'*.sum'): os.unlink(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff2186a-17ce-4a9a-8256-9d05af39fb0e",
   "metadata": {},
   "source": [
    "## Read and plot the earthquakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3939240-c3f9-4e63-bac7-b48d14be4d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "quakes=pd.read_csv(out_good,header=None,names=[\"datetime\",\"latitude\",\"longitude\",\"depth\",\"magnitude\",\"evid\"])\n",
    "print(quakes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb6c27f-2d54-47c6-82f4-a90515468938",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(quakes.longitude,quakes.latitude,20*np.power(3,quakes.magnitude),quakes.depth,edgecolors='k')\n",
    "plt.colorbar(label='depth (m)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f062e5-68bb-4b08-b407-9fbaeafd17c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hypoinv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
